---
title: "The Werewolf Among Us: Humans vs LLMs in Multi-Agent Games"
author:
  - name: Bhavana Jonnalagadda
    orcid: 0009-0009-1054-0995
    corresponding: true
    email: bhavana.jonnalagadda@colorado.edu
    affiliations:
      - name: University of Colorado Boulder
        id: 1
        city: Boulder
        state: CO
  - name: Riley Jones
    email: rjones@colorado.edu
    affiliations:
      - id: 1
keywords:
  - social deduction games
  - persuasion modeling
  - Werewolf Among Us dataset
  - large language models
  - multimodal analysis
abstract: |
  Abstract TODO
date: last-modified
citation:
  container-title: Human vs LLM Multi-Agent Games
---

::: {.content-visible when-format="html"}
::: {.column-margin}
![](Images/logo.png)
:::
:::

# Introduction

<!-- TODO: Broken for some reason?!?!? Fix -->
<!-- ::: {.content-hidden unless-format="latex"}
::: {.callout-tip}
## View Online
This PDF's content, the source code notebooks, along with live interactive versions of all figures (and more!) is available at the website version of this paper: [https://cuboulder-ds.github.io/CSCI-5423-Final](https://cuboulder-ds.github.io/CSCI-5423-Final)
:::
::: -->


- Social deduction games like _Werewolf_ offer a clear way to evaluate how agents deceive, persuade, and reason in group settings[@wikiwerewolf]. In these games, players have limited information, hidden identities, and must convince others while trying to figure out who is lying. These challenges closely match real life situations involving trust, negotiation, and manipulation.

- We wanted to compare how humans and large language models (LLMs) handle these situations. To do this, we used a recent human dataset and constructed one from an LLM-based simulator: 
	- _Werewolf Among Us_ [@laiWerewolfUsMultimodal2022], a collection of real human gameplay annotated with persuasion strategies, 
	- _Werewolf Arena_ [@bailisWerewolfArenaCase2024], a simulated environment where LLM agents play the game autonomously. 
	- While both studies show Werewolf generates complex strategic language, neither compares human and LLM behavior directly.

- Our project addresses this gap. We analyzed transcripts from both datasets, matched them by role, round, and persuasion strategy, and compared how humans and LLMs lie, persuade, and detect deception. 
- By annotating utterances with the same set of persuasive strategies, we clearly show how synthetic agents differ from or resemble humans when navigating deception in adversarial group interactions.


## Related Work

### Multi-Agent LLMs

- Among us game [@chiAMONGAGENTSEvaluatingLarge2024]
- Collective problem solving [@duLargeLanguageModels2024]
  - "analyses indicate that LLM agent groups exhibit more disagreements, complex statements, and a propensity for positive statements compared to human groups"
- Govsim [@piattiCooperateCollapseEmergence2024]
  - "In GOVSIM, a society of AI agents must collectively balance exploiting a common resource with sustaining it for future use. This environment enables the study of how ethical considerations, strategic planning, and negotiation skills impact cooperative outcomes."
- All found similar themes
  - That LLMs are capable and good at understanding the rules
  - That they can cooperate and be sneaky

### LLMs and Werewolf

- Examination of improving werewolf by LLMs [@xuLanguageAgentsReinforcement2024]
  - "our agents use an LLM to perform deductive reasoning and generate a diverse set of action candidates. Then an RL policy trained to optimize the decision-making ability chooses an action from the candidates to play in the game. Extensive experiments show that our agents overcome the intrinsic bias and outperform existing LLM-based agents in the Werewolf game."
- Werewolf Arena [@bailisWerewolfArenaCase2024]
  - Used in this paper
- Explicitly discuss how none of the exisiting LLM+Werewolf papers examine the differences/compare from a human dataset

# Methods

## Data

### Werewolf Among Us Human Dataset

We used the _Werewolf Among Us_ dataset [@laiWerewolfUsMultimodal2022], which contains annotated dialogues from over 150 real games of One Night Werewolf and Avalon. These games differ from classic Werewolf because they have only one round of discussion and voting, do not eliminate players during the game, and include many specialized roles beyond Villager and Werewolf. The dataset provides detailed annotations of persuasion strategies for each utterance, such as accusations, defenses, and identity claims. We specifically used the textual transcriptions and their strategy annotations for our comparisons.

### Werewolf Arena (LLM Dataset)

The _Werewolf Arena_ dataset [@bailisWerewolfArenaCase2024] features simulated classic Werewolf games played by LLM agents without human intervention. Unlike the one-round human games, these simulations involve multiple rounds alternating between night (secret actions) and day (open discussion). Each LLM agent is assigned a role (Villager, Werewolf, Seer, Doctor) and receives context-specific prompts that guide their strategic interactions.

We ran simulations using five LLM models: GPT-4o, GPT-4.1, GPT-4o-mini, DeepSeek-Chat, and DeepSeek-Reasoner. We experimented with two configurations:

- 8 players with 8 rounds of discussion
    
- 10 players with 6 rounds of discussion
    

We chose these configurations to give villagers more time to coordinate, extending the dialogue to better observe persuasive behaviors. After running the simulations, we manually annotated the LLM-generated dialogue using the same persuasion categories as in the human dataset.

## Analysis

We standardized annotations across both datasets so they could be directly compared. Our analyses focused on frequency distributions of persuasion strategies, comparisons by role (villager versus werewolf), and differences in how humans and LLMs applied these strategies.

# Results

{{< embed Data/EDA_Comparison.ipynb#fig-llm-winrounds >}}

{{< embed Data/EDA_Comparison.ipynb#fig-stratbyrole-hum >}}
{{< embed Data/EDA_Comparison.ipynb#fig-stratbyrole-llms >}}

# Discussion and Conclusion

Interpret findings, discuss limitations, and propose future work.

## Limitations

## Future Work

## Summary

Summarize contributions and insights from the project.

---

<!-- See https://quarto.org/docs/authoring/citations.html -->
# References

::: {#refs}
:::

---

# Project Contributions

**Bhavana Jonnalagadda**:

- Paper framework (Quarto) setup
- Github repo management
- EDA on LLM dataset
- Final comparison EDA and results analysis
- Results section
- Discussion and Conclusion section
- Abstract

**Riley Jones**:

- EDA on human dataset
- Werewolf Arena LLM simulation running and data aquisition
- Introduction section
- Methods section
