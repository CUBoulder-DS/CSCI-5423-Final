# CSCI-5423-Final

The final project for CSCI 5423: Biologically inspired multi-agent systems

[Website link](https://cuboulder-ds.github.io/CSCI-5423-Final/)

We present the first direct comparison of human and large language model (LLM) behavior in the classic social deduction game Werewolf, leveraging two annotated datasets: Werewolf Among Us (163 one‐round human games with expert strategy labels) and Werewolf Arena (19 multi‐round LLM simulations across five models). Our analyses revealed that LLM agents secure faster, more decisive wins by focusing their communication on direct calls to action, while human players rely on a richer blend of questioning, accusation, defense, and identity claims. Despite fewer simulated games, LLMs consistently build consensus within early rounds and show predictable voting patterns, highlighting their strength in rapid coordination under structured prompts. However, this comes at the cost of adaptive nuance and evidence‐based persuasion, areas where humans excel through varied strategic interplay. Our findings suggest that enhancing future LLM designs with more balanced strategy repertoires and integrating hybrid human–AI interactions could yield agents capable of both efficient coordination and context‐sensitive reasoning in adversarial group settings.
