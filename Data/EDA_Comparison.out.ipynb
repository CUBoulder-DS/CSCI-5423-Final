{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Werewolf Among Us: Human vs LLM Analysis\n",
    "\n",
    "Bhavana Jonnalagadda"
   ],
   "id": "6e5563dc-bbaf-4c15-9766-6f302b26cb48"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA and comparison of the datasets"
   ],
   "id": "f0a23741-713d-4f80-92ce-8977b010dca5"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:37.501243Z",
      "iopub.status.busy": "2025-05-08T00:59:37.500866Z",
      "iopub.status.idle": "2025-05-08T00:59:37.512366Z",
      "shell.execute_reply": "2025-05-08T00:59:37.511394Z",
      "shell.execute_reply.started": "2025-05-08T00:59:37.501214Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import json\n",
    "import random \n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Viz\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "# pio.renderers.default = \"notebook_connected+plotly_mimetype+png\"\n",
    "# For some reason, the correct setting to get the plots to show up in Quarto HTML?\n",
    "pio.renderers.default = \"notebook_connected+plotly_mimetype+png\""
   ],
   "id": "11a9deb6-25c6-4e9f-8337-9fe325eacbef"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T03:05:56.601553Z",
      "iopub.status.busy": "2025-05-08T03:05:56.601201Z",
      "iopub.status.idle": "2025-05-08T03:05:56.661705Z",
      "shell.execute_reply": "2025-05-08T03:05:56.660738Z",
      "shell.execute_reply.started": "2025-05-08T03:05:56.601528Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "## Plotly graph gen setup\n",
    "\n",
    "# Just have the green more prominent, move red down\n",
    "cust_colorseq = ['#636EFA',\n",
    "                '#00CC96',\n",
    "                '#FFA15A',\n",
    "                '#EF553B',\n",
    "                '#AB63FA',\n",
    "                '#19D3F3',\n",
    "                '#FF6692',\n",
    "                '#B6E880',\n",
    "                '#FF97FF',\n",
    "                '#FECB52']\n",
    "\n",
    "# Generated figure margin\n",
    "mn = 10\n",
    "\n",
    "pio.templates[\"custom\"] = go.layout.Template(layout=go.Layout(\n",
    "        # xaxis=dict(showgrid=False,\n",
    "        #            showline=True,\n",
    "        #            linewidth=2,\n",
    "        #            linecolor=\"black\",\n",
    "        #           ),\n",
    "        #  yaxis=dict(showgrid=False,\n",
    "        #             showline=True,\n",
    "        #            linewidth=2,\n",
    "        #            linecolor=\"black\",\n",
    "        #            ticks=\"outside\", # Show ticks\n",
    "        #            ),\n",
    "        #  paper_bgcolor='rgba(255,255,255,1)',\n",
    "        #  plot_bgcolor='rgba(255,255,255,1)',\n",
    "        #  legend=dict(xanchor=\"right\",\n",
    "        #             yanchor=\"bottom\",\n",
    "        #             y=1.02,\n",
    "        #             x=1,\n",
    "        #             title=dict(text=\"Model\")),\n",
    "        # font=dict(size=15),\n",
    "        margin=dict(l=mn, r=mn, t=mn + 30, b=mn),\n",
    "        colorway=cust_colorseq,\n",
    "                    ),\n",
    "     data=go.layout.template.Data()\n",
    "    )\n",
    "pio.templates.default = \"plotly+custom\"\n",
    "\n",
    "pd.options.display.max_colwidth = 150"
   ],
   "id": "37a4f338-ea25-461c-968c-c2117368748e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ],
   "id": "f67ed8d1-4a9a-4b3e-a57c-cac11cafed93"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-07T03:47:55.877236Z",
      "iopub.status.busy": "2025-05-07T03:47:55.876828Z",
      "iopub.status.idle": "2025-05-07T03:47:56.253360Z",
      "shell.execute_reply": "2025-05-07T03:47:56.252438Z",
      "shell.execute_reply.started": "2025-05-07T03:47:55.877206Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "hum_datapath = os.path.normpath(\"../../Data/Output/EDA_WAU\")\n",
    "llm_datapath = os.path.normpath(\"../../Data/Output/EDA_WA\")\n",
    "\n",
    "hum_rounds_df = pd.read_csv(os.path.join(hum_datapath, \"allrounds.csv\"), index_col=0)\n",
    "hum_text_df = pd.read_csv(os.path.join(hum_datapath, \"alltext.csv\"), index_col=0)\n",
    "hum_text_df[\"strategy\"] = hum_text_df[\"strategy\"].apply(ast.literal_eval)\n",
    "\n",
    "llm_rounds_df = pd.read_csv(os.path.join(llm_datapath, \"allrounds.csv\"), index_col=0)\n",
    "llm_rounds_df[\"players\"] = llm_rounds_df[\"players\"].apply(ast.literal_eval)\n",
    "llm_rounds_df[\"roles\"] = llm_rounds_df[\"roles\"].apply(ast.literal_eval)\n",
    "llm_rounds_df[\"models\"] = llm_rounds_df[\"models\"].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "llm_text_df = pd.read_csv(os.path.join(llm_datapath, \"alltext.csv\"), index_col=0)\n",
    "llm_text_df[\"players\"] = llm_text_df[\"players\"].apply(ast.literal_eval)\n",
    "llm_text_df[\"roles\"] = llm_text_df[\"roles\"].apply(ast.literal_eval)\n",
    "llm_text_df[\"models\"] = llm_text_df[\"models\"].apply(ast.literal_eval)\n",
    "# llm_text_df[\"votes\"] = llm_text_df[\"votes\"].apply(ast.literal_eval, )\n",
    "llm_text_df[\"strategy\"] = llm_text_df[\"strategy\"].apply(ast.literal_eval)"
   ],
   "id": "d2d3f84a-0415-432f-ab11-94130ca1ecd5"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-06T03:54:11.059314Z",
      "iopub.status.busy": "2025-05-06T03:54:11.059001Z",
      "iopub.status.idle": "2025-05-06T03:54:11.077062Z",
      "shell.execute_reply": "2025-05-06T03:54:11.075709Z",
      "shell.execute_reply.started": "2025-05-06T03:54:11.059293Z"
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "hum_rounds_df.head()"
   ],
   "id": "e5337449-ea3b-4666-a9be-feec700862e4"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-07T03:47:57.916544Z",
      "iopub.status.busy": "2025-05-07T03:47:57.916137Z",
      "iopub.status.idle": "2025-05-07T03:47:57.934237Z",
      "shell.execute_reply": "2025-05-07T03:47:57.933120Z",
      "shell.execute_reply.started": "2025-05-07T03:47:57.916506Z"
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "llm_rounds_df.head()"
   ],
   "id": "f629690f-fd5f-4339-b2a2-8a39ea17b955"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:38:04.659366Z",
      "iopub.status.busy": "2025-05-08T00:38:04.658913Z",
      "iopub.status.idle": "2025-05-08T00:38:04.681046Z",
      "shell.execute_reply": "2025-05-08T00:38:04.679978Z",
      "shell.execute_reply.started": "2025-05-08T00:38:04.659336Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "hum_text_df.sample(5).style.set_properties(subset=[\"text\", \"strategy\"], **{\"font-weight\": \"bold\"})"
   ],
   "id": "510f3a88-fa51-4b99-956e-007ee9efb1e5"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T03:11:33.691815Z",
      "iopub.status.busy": "2025-05-08T03:11:33.688371Z",
      "iopub.status.idle": "2025-05-08T03:11:33.752080Z",
      "shell.execute_reply": "2025-05-08T03:11:33.751199Z",
      "shell.execute_reply.started": "2025-05-08T03:11:33.691707Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "llm_text_df.drop(columns=\"votes\").sample(3).style.set_properties(subset=[\"text\", \"strategy\"], **{\"font-weight\": \"bold\"})"
   ],
   "id": "448a6a9f-6836-4325-a660-6dab5eda517c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ],
   "id": "1e7b8039-9acb-4620-8584-862f039e1c6d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General win counts"
   ],
   "id": "ef52c3ba-d74f-4a17-9381-6974218fe6e3"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-06T03:54:21.091316Z",
      "iopub.status.busy": "2025-05-06T03:54:21.090973Z",
      "iopub.status.idle": "2025-05-06T03:54:21.110155Z",
      "shell.execute_reply": "2025-05-06T03:54:21.109350Z",
      "shell.execute_reply.started": "2025-05-06T03:54:21.091289Z"
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "(0.5789473684210527, 19, 0.37423312883435583, 163)"
      ]
     }
    }
   ],
   "source": [
    "llm_outcomes = np.array(llm_rounds_df.groupby(\"game_id\")[\"winner\"].first().tolist()) \n",
    "llm_winperc = np.sum(llm_outcomes == \"Villagers\") / len(llm_outcomes)\n",
    "\n",
    "hum_outcomes = np.array(hum_rounds_df.groupby(\"game_id\")[\"winner\"].first().tolist()) \n",
    "hum_winperc = np.sum(hum_outcomes == \"Villagers\") / len(hum_outcomes)\n",
    "\n",
    "llm_winperc, len(llm_outcomes), hum_winperc, len(hum_outcomes)"
   ],
   "id": "1ef06e65-c97e-44fb-a747-62b5c50c9451"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Source Dataset | Villagers Win | Number of Games |\n",
    "|----------------|---------------|-----------------|\n",
    "| LLMs           | 57.895%       | 19              |\n",
    "| Human          | 37.423%       | 163             |"
   ],
   "id": "00039116-ccb4-4d42-9866-ea9a8dcef5c4"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:46.430522Z",
      "iopub.status.busy": "2025-05-08T00:59:46.430137Z",
      "iopub.status.idle": "2025-05-08T00:59:46.770171Z",
      "shell.execute_reply": "2025-05-08T00:59:46.769180Z",
      "shell.execute_reply.started": "2025-05-08T00:59:46.430495Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "llm_bymodels = llm_rounds_df.explode([\"players\", \"roles\", \"models\"])\n",
    "llm_bymodels[\"won\"] = False\n",
    "llm_bymodels.loc[((llm_bymodels[\"winner\"] == \"Werewolves\") == (llm_bymodels[\"roles\"] == \"Werewolf\")),  \"won\"] = True\n",
    "\n",
    "fig = px.bar(llm_bymodels[[\"models\", \"won\"]].value_counts().reset_index(), x=\"models\", y=\"count\", color=\"won\", barmode=\"stack\")\n",
    "fig.update_layout(xaxis_title=\"LLM Model Used\", height=300)\n",
    "fig.show()"
   ],
   "id": "cell-fig-wins-bymodel"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:48.800438Z",
      "iopub.status.busy": "2025-05-08T00:59:48.800093Z",
      "iopub.status.idle": "2025-05-08T00:59:49.027105Z",
      "shell.execute_reply": "2025-05-08T00:59:49.026276Z",
      "shell.execute_reply.started": "2025-05-08T00:59:48.800413Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "fig = px.violin(llm_bymodels, x=\"roles\", y=\"models\", color=\"won\")\n",
    "fig.update_layout(yaxis_title=\"LLM Model Used\", xaxis_title=\"Player Role\", height=300)\n",
    "fig.show()"
   ],
   "id": "cell-fig-wins-bymodelrole"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:51.105144Z",
      "iopub.status.busy": "2025-05-08T00:59:51.104753Z",
      "iopub.status.idle": "2025-05-08T00:59:51.313270Z",
      "shell.execute_reply": "2025-05-08T00:59:51.312439Z",
      "shell.execute_reply.started": "2025-05-08T00:59:51.105115Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(llm_rounds_df.groupby(\"game_id\")[[\"round\", \"winner\"]].last(), x=\"round\", color=\"winner\")\n",
    "fig.update_layout(title=\"LLM Wins by # of Rounds\", xaxis_title=\"Number of Rounds in the Game\", height=300)\n",
    "fig.show()"
   ],
   "id": "cell-fig-llm-winrounds"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategies used"
   ],
   "id": "1925f251-34cf-44db-8eee-09d92807317f"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:51.456500Z",
      "iopub.status.busy": "2025-05-08T00:59:51.456053Z",
      "iopub.status.idle": "2025-05-08T00:59:51.645551Z",
      "shell.execute_reply": "2025-05-08T00:59:51.644468Z",
      "shell.execute_reply.started": "2025-05-08T00:59:51.456468Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "## Overall strategy used bar plot\n",
    "hum_strats = hum_text_df[\"strategy\"].explode().value_counts().reset_index()\n",
    "llm_strats = llm_text_df[\"strategy\"].explode().value_counts().reset_index()\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(name='Human Strategies', x=hum_strats[\"strategy\"], y=hum_strats[\"count\"], yaxis='y', offsetgroup=1),\n",
    "        go.Bar(name='LLM Strategies', x=llm_strats[\"strategy\"], y=llm_strats[\"count\"], yaxis='y2', offsetgroup=2),\n",
    "    ],\n",
    "    layout={\n",
    "        'yaxis': {'title': 'Human Strategy Use Count'},\n",
    "        'yaxis2': {'title': 'LLM Strategy Use Count', 'overlaying': 'y', 'side': 'right'},\n",
    "        \"title\": \"Overall Strategy Used in Speech\"\n",
    "    }\n",
    ")\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group', height=400)\n",
    "fig.show()"
   ],
   "id": "cell-fig-strat-overall"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:51.648383Z",
      "iopub.status.busy": "2025-05-08T00:59:51.648036Z",
      "iopub.status.idle": "2025-05-08T00:59:51.952410Z",
      "shell.execute_reply": "2025-05-08T00:59:51.950931Z",
      "shell.execute_reply.started": "2025-05-08T00:59:51.648354Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "## Strategy used by player role bar plot\n",
    "hum_strats = hum_text_df[[\"strategy\", \"end_role\"]].explode(\"strategy\").value_counts().reset_index()\n",
    "hum_strats = hum_strats[hum_strats[\"strategy\"] != \"No Strategy\"] # Don't include no strat\n",
    "hum_strats[\"count\"] = hum_strats.groupby(\"end_role\")[\"count\"].transform(lambda x: x/x.sum()) # Make scaled by total strategy use per role\n",
    "\n",
    "fig = px.bar(hum_strats, y=\"end_role\", x=\"count\", color=\"strategy\", barmode=\"group\")\n",
    "fig.update_layout(xaxis_title=\"Ratio of Role's Strategy Use\", yaxis_title=\"Role\", title=\"Humans: Strategy Used by Role\", height=600)\n",
    "fig.show()"
   ],
   "id": "cell-fig-stratbyrole-hum"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:51.955710Z",
      "iopub.status.busy": "2025-05-08T00:59:51.954964Z",
      "iopub.status.idle": "2025-05-08T00:59:52.209781Z",
      "shell.execute_reply": "2025-05-08T00:59:52.208707Z",
      "shell.execute_reply.started": "2025-05-08T00:59:51.955681Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "llm_strats = llm_text_df[[\"players\", \"roles\", \"speaker\", \"strategy\"]].explode([\"players\", \"roles\"])\n",
    "llm_strats = llm_strats[llm_strats[\"players\"] == llm_strats[\"speaker\"]]\n",
    "llm_strats = llm_strats.explode(\"strategy\")[[\"roles\", \"strategy\"]].value_counts().reset_index()\n",
    "llm_strats[\"count\"] = llm_strats.groupby(\"roles\")[\"count\"].transform(lambda x: x/x.sum()) # Make scaled by total strategy use per role\n",
    "\n",
    "fig = px.bar(llm_strats, y=\"roles\", x=\"count\", color=\"strategy\", barmode=\"group\")\n",
    "fig.update_layout(xaxis_title=\"Ratio of Role's Strategy Use\", yaxis_title=\"Role\", title=\"LLMs: Strategy Used by Role\", height=600)\n",
    "fig.show()"
   ],
   "id": "cell-fig-stratbyrole-llms"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:52.212693Z",
      "iopub.status.busy": "2025-05-08T00:59:52.212347Z",
      "iopub.status.idle": "2025-05-08T00:59:52.514915Z",
      "shell.execute_reply": "2025-05-08T00:59:52.513795Z",
      "shell.execute_reply.started": "2025-05-08T00:59:52.212667Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "## Strategy used over time (LLMs)\n",
    "\n",
    "llm_strats_byround = llm_text_df.explode(\"strategy\").groupby(\"round\")[\"strategy\"].value_counts().reset_index()\n",
    "# Make scaled by total strategy use per round\n",
    "llm_strats_byround[\"count\"] = llm_strats_byround.groupby(\"round\")[\"count\"].transform(lambda x: x/x.sum()) \n",
    "\n",
    "fig = px.line(llm_strats_byround, x=\"round\", y=\"count\", color=\"strategy\", markers=True)\n",
    "fig.update_traces(line_width=3)\n",
    "fig.update_layout(yaxis_title=\"Ratio of Round's Strategy Use\", xaxis_title=\"Game Round\", title=\"LLMs: Strategy Use Over Rounds\")\n",
    "fig.show()"
   ],
   "id": "cell-fig-llm-stratbyround"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:52.517832Z",
      "iopub.status.busy": "2025-05-08T00:59:52.517458Z",
      "iopub.status.idle": "2025-05-08T00:59:52.522659Z",
      "shell.execute_reply": "2025-05-08T00:59:52.521681Z",
      "shell.execute_reply.started": "2025-05-08T00:59:52.517803Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "## PCA/Clustering of strategies?"
   ],
   "id": "0e1d6dca-3cb9-4712-b716-611ea92addb5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talking time vs. was voted on\n",
    "\n",
    "Investigating whether a vote was cast upon a person, compared to how much they talked"
   ],
   "id": "23ee87e0-8ec9-448b-8a8e-d9985c9c554c"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:52.524091Z",
      "iopub.status.busy": "2025-05-08T00:59:52.523665Z",
      "iopub.status.idle": "2025-05-08T00:59:52.678271Z",
      "shell.execute_reply": "2025-05-08T00:59:52.677517Z",
      "shell.execute_reply.started": "2025-05-08T00:59:52.524063Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "## Humans dataset\n",
    "hum_talklen = hum_text_df.groupby(\"speaker\")[\"utterance_length\"].sum().reset_index()\n",
    "hum_votedon = hum_rounds_df[\"voted_for\"].value_counts().reset_index()\n",
    "cmp = hum_talklen.merge(hum_votedon, left_on=\"speaker\", right_on=\"voted_for\", how=\"inner\")\\\n",
    "                .rename(columns={\"speaker\": \"Player\", \"utterance_length\": \"Total talking time\", \"count\": \"Was voted for\"})\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(name='Total talking time', x=cmp[\"Player\"], y=cmp[\"Total talking time\"], yaxis='y', offsetgroup=1),\n",
    "        go.Bar(name='Was voted for', x=cmp[\"Player\"], y=cmp[\"Was voted for\"], yaxis='y2', offsetgroup=2)\n",
    "    ],\n",
    "    layout={\n",
    "        'yaxis': {'title': 'Total talking time'},\n",
    "        'yaxis2': {'title': 'Was voted for', 'overlaying': 'y', 'side': 'right'},\n",
    "        \"title\": \"Humans: Player Talking Time vs. Was Voted On\"\n",
    "    }\n",
    ")\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group', height=400)\n",
    "fig.show()"
   ],
   "id": "cell-fig-talking-hum"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:52.991844Z",
      "iopub.status.busy": "2025-05-08T00:59:52.991207Z",
      "iopub.status.idle": "2025-05-08T00:59:53.144457Z",
      "shell.execute_reply": "2025-05-08T00:59:53.143566Z",
      "shell.execute_reply.started": "2025-05-08T00:59:52.991816Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "## LLMs dataset\n",
    "llm_talklen = llm_text_df[\"speaker\"].value_counts().reset_index()\n",
    "llm_votes = llm_text_df.groupby([\"game_id\", \"round\"])[\"votes\"].first().reset_index().dropna()[\"votes\"].apply(ast.literal_eval)\n",
    "voted_on = {}\n",
    "for vote in llm_votes:\n",
    "    for k, v in vote.items():\n",
    "        if not k in voted_on:\n",
    "            voted_on[k] = 1\n",
    "        else:\n",
    "            voted_on[k] += 1\n",
    "llm_votedon = pd.DataFrame(voted_on.items()).rename(columns={0: \"speaker\", 1: \"Voted On\"})\n",
    "\n",
    "cmp = llm_talklen.merge(llm_votedon, on=\"speaker\", how=\"inner\")\\\n",
    "                .rename(columns={\"speaker\": \"Player\", \"count\": \"Number of Speeches\"})\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(name='Number of Speeches', x=cmp[\"Player\"], y=cmp[\"Number of Speeches\"], yaxis='y', offsetgroup=1),\n",
    "        go.Bar(name='Was voted for', x=cmp[\"Player\"], y=cmp[\"Voted On\"], yaxis='y2', offsetgroup=2)\n",
    "    ],\n",
    "    layout={\n",
    "        'yaxis': {'title': 'Number of Speeches'},\n",
    "        'yaxis2': {'title': 'Was voted for', 'overlaying': 'y', 'side': 'right'},\n",
    "        \"title\": \"LLMs: Player Talking Time vs. Was Voted On\"\n",
    "    }\n",
    ")\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group', height=400)\n",
    "fig.show()"
   ],
   "id": "cell-fig-talking-llm"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting spread\n",
    "\n",
    "How unified vs spread out the votes were per round"
   ],
   "id": "7e06c822-b3f4-4ce7-9a73-ab368132f9ac"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:53.588208Z",
      "iopub.status.busy": "2025-05-08T00:59:53.587617Z",
      "iopub.status.idle": "2025-05-08T00:59:53.799706Z",
      "shell.execute_reply": "2025-05-08T00:59:53.798773Z",
      "shell.execute_reply.started": "2025-05-08T00:59:53.588184Z"
     }
    }
   },
   "outputs": [],
   "source": [
    "def human_spread(group):\n",
    "    # Drop NaN or None values in voted_for\n",
    "    votes = group['voted_for'].dropna()\n",
    "    # Count the votes\n",
    "    vote_counts = votes.value_counts()\n",
    "    if len(vote_counts) == 0:\n",
    "        return 0\n",
    "    # Get most voted for person / total votes\n",
    "    return vote_counts.iloc[0] / len(group)\n",
    "hum_vote_spread = hum_rounds_df.groupby(\"game_id\").apply(human_spread).reset_index()[0]\n",
    "\n",
    "llm_vote_spread = []\n",
    "for vote in llm_votes:\n",
    "    llm_vote_spread.append(Counter(vote.values()).most_common(1)[0][1] / len(vote))\n",
    "\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Histogram(name='Human Voter Spread', x=hum_vote_spread, opacity=0.75, yaxis='y', offsetgroup=1),\n",
    "        go.Histogram(name='LLM Voter Spread', x=llm_vote_spread, opacity=0.75, yaxis='y2', offsetgroup=2),\n",
    "    ],\n",
    "    layout=dict(\n",
    "        title=\"Spread of Votes\",\n",
    "        xaxis=dict(title=\"Ratio of Players That Voted for Top Choice\"),\n",
    "        yaxis={\"title\": \"Human Count\"},\n",
    "        yaxis2={'overlaying': 'y', 'side': 'right', \"title\": \"LLM Count\"},\n",
    "    )\n",
    ")\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='overlay', height=400)\n",
    "fig.show()"
   ],
   "id": "cell-fig-voting-spread"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-08T00:59:54.134805Z",
      "iopub.status.busy": "2025-05-08T00:59:54.134260Z",
      "iopub.status.idle": "2025-05-08T00:59:54.147574Z",
      "shell.execute_reply": "2025-05-08T00:59:54.146902Z",
      "shell.execute_reply.started": "2025-05-08T00:59:54.134779Z"
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "0        I don't know why this is necessary considering saw the card.\n",
       "1                                                    I am a Villager.\n",
       "2                                                       Like, I mean-\n",
       "3                                                       But, I-I-I-I-\n",
       "4             Continue. Well, I guess we don't really need to, do we?\n",
       "                                     ...                             \n",
       "21067                                                       We could.\n",
       "21068                                                          Justin\n",
       "21069                               It's just Justin, Justin, Justin.\n",
       "21070                                                 Just inception.\n",
       "21071                                       So we're voting Mitchell?\n",
       "Name: text, Length: 21072, dtype: object"
      ]
     }
    }
   ],
   "source": [
    "hum_text_df[\"text\"]"
   ],
   "id": "bc78e77d-ec78-418f-90d2-24f4dbab7792"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "quarto-private-1": {
     "key": "execution",
     "value": {
      "iopub.execute_input": "2025-05-01T17:53:19.316323Z",
      "iopub.status.busy": "2025-05-01T17:53:19.315793Z",
      "iopub.status.idle": "2025-05-01T17:53:19.324378Z",
      "shell.execute_reply": "2025-05-01T17:53:19.323164Z",
      "shell.execute_reply.started": "2025-05-01T17:53:19.316287Z"
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "0      Alright everyone, it's unfortunate that we've ...\n",
       "1      Thanks, Will. It's indeed a tough start losing...\n",
       "2      Thanks, Hayley. I agree with you and Will that...\n",
       "3      Jacob, I appreciate you pointing out that I wa...\n",
       "4      Thanks for addressing that, Jackson. I complet...\n",
       "                             ...                        \n",
       "250    Hayley, your accusations are unfounded and ser...\n",
       "251    Harold, your insistence on labeling me as the ...\n",
       "252    Hayley, your tactics of distraction are transp...\n",
       "253    I want to echo what Harold has shared with us:...\n",
       "254    I appreciate the spirited debate, but it's cru...\n",
       "Name: text, Length: 255, dtype: object"
      ]
     }
    }
   ],
   "source": [
    "llm_text_df[\"text\"]"
   ],
   "id": "8521acdd-0902-4b72-a4d4-52a884b51584"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bailis, Suma, Jane Friedhoff, and Feiyang Chen. 2024. “Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction.” July 18, 2024. <https://doi.org/10.48550/arXiv.2407.13943>.\n",
    "\n",
    "Chi, Yizhou, Lingjun Mao, and Zineng Tang. 2024. “AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game.” July 24, 2024. <https://doi.org/10.48550/arXiv.2407.16521>.\n",
    "\n",
    "Cho, Young-Min, Raphael Shu, Nilaksh Das, Tamer Alkhouli, Yi-An Lai, Jason Cai, Monica Sunkara, and Yi Zhang. 2024. “RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration.” November 11, 2024. <https://doi.org/10.48550/arXiv.2411.07161>.\n",
    "\n",
    "Du, Yinuo, Prashanth Rajivan, and Cleotilde Gonzalez. 2024. “Large Language Models for Collective Problem-Solving: Insights into Group Consensus Decision-Making.” *Proceedings of the Annual Meeting of the Cognitive Science Society* 46 (0). <https://escholarship.org/uc/item/6s060914>.\n",
    "\n",
    "Lai, Bolin, Hongxin Zhang, Miao Liu, Aryan Pariani, Fiona Ryan, Wenqi Jia, Shirley Anugrah Hayati, James M. Rehg, and Diyi Yang. 2022. “Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games.” December 16, 2022. <https://doi.org/10.48550/arXiv.2212.08279>.\n",
    "\n",
    "Piatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Schölkopf, Mrinmaya Sachan, and Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents.” *Advances in Neural Information Processing Systems* 37 (December): 111715–59. <https://proceedings.neurips.cc/paper_files/paper/2024/hash/ca9567d8ef6b2ea2da0d7eed57b933ee-Abstract-Conference.html>.\n",
    "\n",
    "Stepputtis, Simon, Joseph Campbell, Yaqi Xie, Zhengyang Qi, Wenxin Sharon Zhang, Ruiyi Wang, Sanketh Rangreji, Charles Michael Lewis, and Katia P. Sycara. 2023. “Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models.” In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*. <https://openreview.net/forum?id=JKmsjKJ0Q8>.\n",
    "\n",
    "Wikipedia contributors. 2024. “Mafia (Party Game).” <https://en.wikipedia.org/wiki/Mafia_(party_game)>.\n",
    "\n",
    "Xu, Zelai, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. 2024. “Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game.” February 20, 2024. <https://doi.org/10.48550/arXiv.2310.18940>."
   ],
   "id": "d368af02-87e9-4063-94a2-c654dcdd63ce"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
